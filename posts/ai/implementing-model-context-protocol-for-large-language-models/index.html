<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en-us lang=en-us><head><script defer language=javascript type=text/javascript src=/js/bundle.min.11d62625e7495f8147fccf5d08f37bded574a50c4508c235cc666848567d99ab.js></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=icon href=/favicon.png><title itemprop=name>Go Sang - Implementing Model Context Protocol for Large Language Models</title><meta property="og:title" content="Go Sang - Implementing Model Context Protocol for Large Language Models"><meta name=twitter:title content="Go Sang - Implementing Model Context Protocol for Large Language Models"><meta itemprop=name content="Go Sang - Implementing Model Context Protocol for Large Language Models"><meta name=application-name content="Go Sang - Implementing Model Context Protocol for Large Language Models"><meta property="og:site_name" content><meta name=description content><meta itemprop=description content><meta property="og:description" content><meta name=twitter:description content><base href=https://gosang.github.io/posts/ai/implementing-model-context-protocol-for-large-language-models/><link rel=canonical href=https://gosang.github.io/posts/ai/implementing-model-context-protocol-for-large-language-models/ itemprop=url><meta name=url content="https://gosang.github.io/posts/ai/implementing-model-context-protocol-for-large-language-models/"><meta name=twitter:url content="https://gosang.github.io/posts/ai/implementing-model-context-protocol-for-large-language-models/"><meta property="og:url" content="https://gosang.github.io/posts/ai/implementing-model-context-protocol-for-large-language-models/"><meta property="og:updated_time" content="22003-22-12T327:06:25+0100"><link rel=sitemap type=application/xml title=Sitemap href=https://gosang.github.io/sitemap.xml><meta name=robots content="index,follow"><meta name=googlebot content="index,follow"><meta name=twitter:site content><meta name=twitter:creator content><meta property="fb:admins" content><meta name=apple-mobile-web-app-title content><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="black"><meta property="og:type" content="article"><meta property="article:publisher" content><meta property="og:article:published_time" content="22003-22-12T327:06:25+0100"><meta property="article:published_time" content="22003-22-12T327:06:25+0100"><script defer type=application/ld+json>{"@context":"http://schema.org","@type":"Article","headline":"Implementing Model Context Protocol for Large Language Models","author":{"@type":"Person","name":"https:\/\/github.com\/gosang"},"datePublished":"2025-03-22","description":"","wordCount":"754","mainEntityOfPage":"True","dateModified":"2025-03-22","image":{"@type":"imageObject","url":""},"publisher":{"@type":"Organization","name":"","logo":{"@type":"imageObject","url":""}}}</script><meta name=generator content="Hugo 0.119.0"><link type=text/css rel=stylesheet href=/css/bundle.min.178e339ccb9acabffeebf9adbb0bb23c1ec0b72a2a50edee18a5007d4d5a68aa.css><style>body{--sidebar-bg-color:#202020;--sidebar-img-border-color:#515151;--sidebar-p-color:#909090;--sidebar-h1-color:#FFF;--sidebar-a-color:#FFF;--sidebar-socials-color:#FFF;--text-color:#222;--bkg-color:#FAF9F6;--post-title-color:#303030;--list-color:#5a5a5a;--link-color:#268bd2;--date-color:#515151;--table-border-color:#E5E5E5;--table-stripe-color:#F9F9F9;--code-color:#bf616a;--code-background-color:#E5E5E5;--moon-sun-color:#FFF;--moon-sun-background-color:#515151}body.dark-theme{--text-color:#eee;--bkg-color:#121212;--post-title-color:#DBE2E9;--list-color:#9d9d9d;--link-color:#268bd2;--date-color:#9a9a9a;--table-border-color:#515151;--table-stripe-color:#202020;--code-color:#ff7f7f;--code-background-color:#393D47}body{background-color:var(--bkg-color)}</style></head><body><div class=wrapper><aside class=sidebar><div class="container sidebar-sticky"><div class=light-dark align=right><button class=btn-light-dark title="Toggle light/dark mode"><svg class="moon" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 16 16"><path fill="currentcolor" d="M6 .278a.768.768.0 01.08.858 7.208 7.208.0 00-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527.0 1.04-.055 1.533-.16a.787.787.0 01.81.316.733.733.0 01-.031.893A8.349 8.349.0 018.344 16C3.734 16 0 12.286.0 7.71.0 4.266 2.114 1.312 5.124.06A.752.752.0 016 .278z"/></svg><svg class="sun" xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" viewBox="0 0 16 16"><path fill="currentcolor" d="M8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.5.5.0 01.5.5v2a.5.5.0 01-1 0v-2A.5.5.0 018 0zm0 13a.5.5.0 01.5.5v2a.5.5.0 01-1 0v-2A.5.5.0 018 13zm8-5a.5.5.0 01-.5.5h-2a.5.5.0 010-1h2a.5.5.0 01.5.5zM3 8a.5.5.0 01-.5.5h-2a.5.5.0 010-1h2A.5.5.0 013 8zm10.657-5.657a.5.5.0 010 .707l-1.414 1.415a.5.5.0 11-.707-.708l1.414-1.414a.5.5.0 01.707.0zm-9.193 9.193a.5.5.0 010 .707L3.05 13.657a.5.5.0 01-.707-.707l1.414-1.414a.5.5.0 01.707.0zm9.193 2.121a.5.5.0 01-.707.0l-1.414-1.414a.5.5.0 01.707-.707l1.414 1.414a.5.5.0 010 .707zM4.464 4.465a.5.5.0 01-.707.0L2.343 3.05a.5.5.0 11.707-.707l1.414 1.414a.5.5.0 010 .708z"/></svg></button></div><div class=sidebar-about><h1 class=brand><a href=https://gosang.github.io/><h1>Go Sang</h1></a></h1><p class=lead>Learning about technology.</p></div><nav><ul class=sidebar-nav><li class=heading><a href=/posts/>Posts</a></li><li class=sub-heading>Recent</li><li class=bullet><a href=https://gosang.github.io/posts/caching/implementing-distributed-caching-in-asp-dotnet-core-with-redis/>Implementing Distributed Caching in ASP.NET Core with Redis</a></li><li class=bullet><a href=https://gosang.github.io/posts/ai/implementing-model-context-protocol-for-large-language-models/>Implementing Model Context Protocol for Large Language Models</a></li><li class=bullet><a href=https://gosang.github.io/posts/ai/retrieval-augmented-generation-architecture-patterns/>Retrieval Augmented Generation Architecture Patterns</a></li><li class=bullet><a href=https://gosang.github.io/posts/dotnet/implementing-range-based-pagination-with-mongodb-csharp-driver-in-asp-dotnet-core/>Implementing Range-Based Pagination with MongoDB C# Driver in ASP.NET Core 8</a></li><li class=bullet><a href=https://gosang.github.io/posts/dotnet/implementing-pagination-with-mongodb-csharp-driver-in-asp-dotnet-core/>Implementing Pagination with MongoDB C# Driver in ASP.NET Core 8</a></li></ul></nav><a target=_blank class=social title=GitHub href=https://github.com/gosang><svg xmlns="http://www.w3.org/2000/svg" width="1.2em" height="1.2em" viewBox="-2 -2 24 24"><path fill="currentcolor" d="M18.88 1.099C18.147.366 17.265.0 16.233.0H3.746C2.714.0 1.832.366 1.099 1.099.366 1.832.0 2.714.0 3.746v12.487c0 1.032.366 1.914 1.099 2.647.733.733 1.615 1.099 2.647 1.099H6.66c.19.0.333-.007.429-.02a.504.504.0 00.286-.169c.095-.1.143-.245.143-.435l-.007-.885c-.004-.564-.006-1.01-.006-1.34l-.3.052c-.19.035-.43.05-.721.046a5.555 5.555.0 01-.904-.091 2.026 2.026.0 01-.872-.39 1.651 1.651.0 01-.572-.8l-.13-.3a3.25 3.25.0 00-.41-.663c-.186-.243-.375-.407-.566-.494l-.09-.065a.956.956.0 01-.17-.156.723.723.0 01-.117-.182c-.026-.061-.004-.111.065-.15.07-.04.195-.059.378-.059l.26.04c.173.034.388.138.643.311a2.1 2.1.0 01.631.677c.2.355.44.626.722.813.282.186.566.28.852.28.286.0.533-.022.742-.065a2.59 2.59.0 00.585-.196c.078-.58.29-1.028.637-1.34a8.907 8.907.0 01-1.333-.234 5.314 5.314.0 01-1.223-.507 3.5 3.5.0 01-1.047-.872c-.277-.347-.505-.802-.683-1.365-.177-.564-.266-1.215-.266-1.952.0-1.049.342-1.942 1.027-2.68-.32-.788-.29-1.673.091-2.652.252-.079.625-.02 1.119.175.494.195.856.362 1.086.5.23.14.414.257.553.352a9.233 9.233.0 012.497-.338c.859.0 1.691.113 2.498.338l.494-.312a6.997 6.997.0 011.197-.572c.46-.174.81-.221 1.054-.143.39.98.424 1.864.103 2.653.685.737 1.028 1.63 1.028 2.68.0.737-.089 1.39-.267 1.957-.177.568-.407 1.023-.689 1.366a3.65 3.65.0 01-1.053.865c-.42.234-.828.403-1.223.507a8.9 8.9.0 01-1.333.235c.45.39.676 1.005.676 1.846v3.11c0 .147.021.266.065.357a.36.36.0 00.208.189c.096.034.18.056.254.064.074.01.18.013.318.013h2.914c1.032.0 1.914-.366 2.647-1.099.732-.732 1.099-1.615 1.099-2.647V3.746c0-1.032-.367-1.914-1.1-2.647z"/></svg></a><a target=_blank class=social title="RSS Feed" href=https://gosang.github.io//posts/index.xml><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1.2em" viewBox="0 0 1280 1280"><g transform="translate(0.000000,1280.000000) scale(0.100000,-0.100000)" fill="currentcolor"><path d="M2295 11929c-284-12-642-45-707-65-17-5-18-63-18-1039 0-569 4-1036 8-1039 5-3 74 6 153 19 510 86 1168 95 1789 25 1348-153 2602-677 3670-1531 385-308 820-744 1126-1129 842-1060 1362-2313 1514-3650 70-621 61-1279-25-1789-13-79-22-148-19-153 3-4 471-8 1039-8h1035l5 23c51 225 85 942 67 1419-23 605-77 1044-198 1617-294 14e2-927 2734-1823 3846-1043 1295-2364 2259-3909 2854-1158 447-2451 656-3707 6e2z"/><path d="M2255 7845c-269-25-620-81-667-106-17-9-18-55-18-899 0-706 3-890 13-890 6 0 66 18 132 41 130 44 288 79 467 105 154 21 577 30 749 15 1207-107 2267-823 2814-1902 166-327 268-637 330-1001 38-227 48-384 42-662-8-348-44-590-126-831-23-66-41-126-41-132 0-10 184-13 890-13 844 0 890 1 899 18 27 50 88 452 110 725 14 162 14 624 1 782-59 703-233 1323-545 1945-481 956-1313 1788-2270 2268-620 310-1239 483-1940 542-165 14-669 10-840-5z"/><path d="M2519 3815c-391-66-725-336-868-703-79-201-96-462-45-677 83-344 338-641 666-774 116-47 205-69 330-80 412-39 811 153 1040 5e2 193 292 240 648 128 981-135 403-492 699-914 757-1e2 14-241 12-337-4z"/></g></svg></a><p class=footnote>powered by <a target=_blank href=https://gohugo.io>Hugo</a> | themed with <a target=_blank href=https://github.com/lukeorth/poison>poison</a><br>&copy; 2025 . All rights reserved.</p></div></aside><main class="content container"><div class=post><div class=info><h1 class=post-title><a href=https://gosang.github.io/posts/ai/implementing-model-context-protocol-for-large-language-models/>Implementing Model Context Protocol for Large Language Models</a></h1><time datetime=2025-03-22T12:27:06+0100 class=post-date>March 22, 2025</time><ul class=tags><li class=tag-MCP><a href=https://gosang.github.io/tags/mcp>MCP</a></li><li class=tag-LLM><a href=https://gosang.github.io/tags/llm>LLM</a></li></ul></div><p>As LLMs become increasingly central to modern software applications, one persistent challenge is managing how models retain, reference, and interact with context across different interactions. This is where Model Context Protocol (MCP) comes into play ‚Äî an architectural pattern and protocol designed to optimize, standardize, and streamline how context is managed in LLM-powered systems.</p><p>In this blog post, we‚Äôll explore:</p><ul><li>What MCP is</li><li>Why it‚Äôs important</li><li>Key concepts and functions</li><li>How to implement it</li><li>Pros and cons</li><li>Use cases, issues, and best practices</li></ul><h1 id=-what-is-model-context-protocol-mcp>üìå What is Model Context Protocol (MCP)?</h1><p>Model Context Protocol (MCP) is a structured framework or protocol designed to manage the contextual memory and state of a conversation or task handled by a large language model. It defines how context (e.g., history, goals, user preferences, task progress) is structured, stored, retrieved, and injected into interactions with the model.</p><p>MCP is not a single library or tool ‚Äî it‚Äôs a design pattern or architecture that can be implemented using various tools (e.g., vector databases, metadata tagging, session management).</p><h2 id=-why-mcp>‚úÖ Why MCP?</h2><p>LLMs, even advanced ones like GPT-4 or Claude, are stateless by design. They process inputs without any inherent memory of prior interactions unless context is passed manually.</p><p>Without MCP, systems face:</p><ul><li>Redundant prompts</li><li>Loss of task continuity</li><li>Higher token usage (more expensive)</li><li>Poor user experience</li></ul><p>By applying MCP, developers can:</p><ul><li>Preserve context across long interactions</li><li>Inject relevant prior knowledge</li><li>Minimize prompt engineering</li><li>Enable multi-turn, goal-oriented conversations</li></ul><h2 id=-key-concepts>üß† Key Concepts</h2><p>Here are the essential building blocks of MCP:</p><table><thead><tr><th>Component</th><th>Description</th></tr></thead><tbody><tr><td>Session Context</td><td>A data object representing the current interaction scope</td></tr><tr><td>Context Store</td><td>Persistent memory (DB/vector store) for storing prior interactions/data</td></tr><tr><td>Retriever</td><td>A function to fetch relevant context snippets dynamically</td></tr><tr><td>Injector</td><td>Merges retrieved context with the new prompt in a structured format</td></tr><tr><td>Context Policy</td><td>Rules defining what gets stored, for how long, and when it should be used</td></tr></tbody></table><h1 id=-implementing-mcp-for-llms-step-by-step>üîß Implementing MCP for LLMs (Step-by-Step)</h1><p>Here‚Äôs a simplified implementation example using Python and LangChain with a vector database (e.g., FAISS or Pinecone).</p><h4 id=1-define-the-session-context>1. Define the Session Context</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>SessionContext</span>:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, session_id):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>session_id <span style=color:#f92672>=</span> session_id
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>metadata <span style=color:#f92672>=</span> {}
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>history <span style=color:#f92672>=</span> []  <span style=color:#75715e># Can include user inputs, model responses, task metadata</span>
</span></span></code></pre></div><h4 id=2-store-context-in-a-vector-db>2. Store Context in a Vector DB</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.vectorstores <span style=color:#f92672>import</span> FAISS
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain.embeddings <span style=color:#f92672>import</span> OpenAIEmbeddings
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>vector_store <span style=color:#f92672>=</span> FAISS(OpenAIEmbeddings())
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>store_context</span>(session_ctx, text):
</span></span><span style=display:flex><span>    vector_store<span style=color:#f92672>.</span>add_texts([text], metadatas<span style=color:#f92672>=</span>[{<span style=color:#e6db74>&#34;session&#34;</span>: session_ctx<span style=color:#f92672>.</span>session_id}])
</span></span></code></pre></div><h4 id=3-retrieve-relevant-context>3. Retrieve Relevant Context</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>retrieve_context</span>(session_ctx, query, top_k<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> vector_store<span style=color:#f92672>.</span>similarity_search(query, k<span style=color:#f92672>=</span>top_k, filter<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;session&#34;</span>: session_ctx<span style=color:#f92672>.</span>session_id})
</span></span></code></pre></div><h4 id=4-inject-context-into-prompt>4. Inject Context into Prompt</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_prompt</span>(context_snippets, user_input):
</span></span><span style=display:flex><span>    context_block <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>join([<span style=color:#e6db74>&#34;- &#34;</span> <span style=color:#f92672>+</span> snippet<span style=color:#f92672>.</span>page_content <span style=color:#66d9ef>for</span> snippet <span style=color:#f92672>in</span> context_snippets])
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;&#34;&#34;Context:</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>{</span>context_block<span style=color:#e6db74>}</span><span style=color:#ae81ff>\n\n</span><span style=color:#e6db74>User Input:</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>{</span>user_input<span style=color:#e6db74>}</span><span style=color:#ae81ff>\n\n</span><span style=color:#e6db74>Response:&#34;&#34;&#34;</span>
</span></span></code></pre></div><h4 id=5-llm-invocation>5. LLM Invocation</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.llms <span style=color:#f92672>import</span> OpenAI
</span></span><span style=display:flex><span>llm <span style=color:#f92672>=</span> OpenAI()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>context_snippets <span style=color:#f92672>=</span> retrieve_context(session_ctx, user_input)
</span></span><span style=display:flex><span>prompt <span style=color:#f92672>=</span> create_prompt(context_snippets, user_input)
</span></span><span style=display:flex><span>response <span style=color:#f92672>=</span> llm(prompt)
</span></span></code></pre></div><p>This approach can scale with Redis, Pinecone, Weaviate, or PostgreSQL for context storage.</p><h1 id=-advantages-of-mcp>üìä Advantages of MCP</h1><table><thead><tr><th>Benefit</th><th>Description</th></tr></thead><tbody><tr><td>üîÅ Continuity</td><td>Enables multi-turn, task-based dialogues without re-explaining</td></tr><tr><td>üí∏ Efficiency</td><td>Reduces prompt size by retrieving only relevant info</td></tr><tr><td>üîí Consistency</td><td>Ensures repeated interactions follow the same context rules</td></tr><tr><td>üß± Modularity</td><td>Makes LLM applications composable and maintainable</td></tr></tbody></table><h1 id=-disadvantages-of-mcp>‚ö†Ô∏è Disadvantages of MCP</h1><table><thead><tr><th>Limitation</th><th>Details</th></tr></thead><tbody><tr><td>üß† Memory Overhead</td><td>Requires extra infrastructure (vector DB, retrievers)</td></tr><tr><td>ü§ñ Imperfect Retrieval</td><td>Irrelevant context may be retrieved if embeddings are noisy</td></tr><tr><td>üîÑ State Drift</td><td>Without periodic context cleanup, outdated info may persist</td></tr><tr><td>üï∞Ô∏è Latency</td><td>Real-time retrieval and merging can introduce delays</td></tr></tbody></table><h1 id=-use-cases>üß∞ Use Cases</h1><ul><li><strong>Conversational Agents</strong> (e.g., customer support, AI companions)</li><li><strong>Educational Tutors</strong> maintaining learning progress</li><li><strong>Code Assistants</strong> retaining project-specific context</li><li><strong>Healthcare Assistants</strong> tracking patient interactions over time</li><li><strong>Legal/Financial Analysis</strong> referencing past casework or documents</li></ul><h1 id=-issues-and-considerations>üöß Issues and Considerations</h1><table><thead><tr><th>Concern</th><th>Mitigation</th></tr></thead><tbody><tr><td><strong>Data Privacy</strong></td><td>Use encryption and role-based access control in context storage</td></tr><tr><td><strong>Scalability</strong></td><td>Index sharding or hybrid retrieval (semantic + keyword)</td></tr><tr><td><strong>Token Limits</strong></td><td>Prioritize most relevant context only; consider summarization</td></tr><tr><td><strong>Relevance</strong></td><td>Use metadata filters, time decay, and context weighting</td></tr></tbody></table><h1 id=-best-practices>üßë‚Äçüè´ Best Practices</h1><ul><li>Use <strong>structured metadata</strong> with each stored context chunk (e.g., timestamp, task, session).</li><li>Apply <strong>embedding quality checks</strong> (e.g., cosine similarity thresholds).</li><li>Set <strong>retention policies</strong> ‚Äî discard stale or irrelevant data.</li><li>Combine <strong>retrieval-augmented generation</strong> (RAG) techniques.</li><li>Ensure <strong>context interpretability</strong> ‚Äî clearly distinguish retrieved vs user content.</li></ul><h1 id=-conclusion>üîö Conclusion</h1><p>Model Context Protocol (MCP) is a crucial enabler for building intelligent, stateful, and scalable LLM-based applications. By formalizing how we manage context ‚Äî what gets stored, retrieved, and injected ‚Äî developers can achieve dramatically better performance, cost-efficiency, and user experience.</p><p>Whether you&rsquo;re building a chatbot, tutoring system, or enterprise agent, implementing MCP is a powerful way to bring long-term memory and personalization to your AI systems.</p><h1 id=-references>üìö References</h1><ul><li><a href=https://python.langchain.com/docs/introduction/ target=_blank>LangChain Documentation</a></li><li><a href=https://platform.openai.com/docs/guides/gpt-best-practices target=_blank>OpenAI - Context and Memory</a></li><li><a href=https://github.com/facebookresearch/faiss target=_blank>FAISS - Facebook AI Similarity Search</a></li><li><a href>Pinecone Documentation</a></li><li><a href=https://arxiv.org/abs/2005.11401 target=_blank>Retrieval-Augmented Generation (RAG)</a></li></ul><hr><div class=footer><a class=previous-post href="https://gosang.github.io/posts/ai/retrieval-augmented-generation-architecture-patterns/?ref=footer"><span style=font-weight:700>¬´ Previous</span><br>Retrieval Augmented Generation Architecture...</a><div class=next-post><a href="https://gosang.github.io/posts/caching/implementing-distributed-caching-in-asp-dotnet-core-with-redis/?ref=footer"><span style=font-weight:700>Next ¬ª</span><br>Implementing Distributed Caching in ASP.NET Core...</a></div></div></div></main><div class=article-toc><div class=toc-wrapper><h4 id=contents></h4><nav id=TableOfContents><ul><li><a href=#-why-mcp>‚úÖ Why MCP?</a></li><li><a href=#-key-concepts>üß† Key Concepts</a></li></ul><ul><li><ul><li></li></ul></li></ul></nav></div></div></div></body></html>